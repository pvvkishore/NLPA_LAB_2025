{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOKXDVOS4Bo7Npy/pbWBNbi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pvvkishore/NLPA_LAB_2025/blob/main/Basic_ANN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qov8k0KvAtKf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # Clip to prevent overflow\n",
        "\n",
        "# Data for binary classification\n",
        "X = np.array([[2, 1], [1, 3], [3, 2], [1, 1], [4, 1], [2, 4]])  # Features [x1, x2]\n",
        "y = np.array([1, 0, 1, 0, 1, 0])  # Binary labels: 1=positive, 0=negative\n",
        "\n",
        "print(\"Single Neuron Binary Classifier\")\n",
        "print(\"Data points [x1, x2] and labels:\")\n",
        "for i in range(len(X)):\n",
        "    print(f\"X{i+1}: {X[i]} → y{i+1}: {y[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameters (following your structure)\n",
        "w1 = 0.1  # Weight for x1\n",
        "w2 = 0.1  # Weight for x2\n",
        "b = 0.0   # Bias\n",
        "epochs = 50\n",
        "n = len(X)\n",
        "learning_rate = 0.5\n",
        "\n",
        "print(f\"\\nInitial parameters: w1={w1}, w2={w2}, b={b}\")\n",
        "print(f\"Learning rate: {learning_rate}\")\n",
        "print(f\"Number of epochs: {epochs}\")\n",
        "print(\"\\nTraining Progress:\")\n",
        "print(\"Epoch | Loss (Binary Cross-Entropy) | Accuracy\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "9oQFgtp7A99u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # Clip to prevent overflow\n",
        "\n",
        "# Data for binary classification\n",
        "X = np.array([[2, 1], [1, 3], [3, 2], [1, 1], [4, 1], [2, 4]])  # Features [x1, x2]\n",
        "y = np.array([1, 0, 1, 0, 1, 0])  # Binary labels: 1=positive, 0=negative\n",
        "\n",
        "print(\"Single Neuron Binary Classifier\")\n",
        "print(\"Data points [x1, x2] and labels:\")\n",
        "for i in range(len(X)):\n",
        "    print(f\"X{i+1}: {X[i]} → y{i+1}: {y[i]}\")\n",
        "\n",
        "# Initialize parameters (following your structure)\n",
        "w1 = 0.1  # Weight for x1\n",
        "w2 = 0.1  # Weight for x2\n",
        "b = 0.0   # Bias\n",
        "epochs = 50\n",
        "n = len(X)\n",
        "learning_rate = 0.5\n",
        "\n",
        "print(f\"\\nInitial parameters: w1={w1}, w2={w2}, b={b}\")\n",
        "print(f\"Learning rate: {learning_rate}\")\n",
        "print(f\"Number of epochs: {epochs}\")\n",
        "print(\"\\nTraining Progress:\")\n",
        "print(\"Epoch | Loss (Binary Cross-Entropy) | Accuracy\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Training loop (following your structure)\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    # Process each data point (following your inner loop structure)\n",
        "    for i in range(n):\n",
        "        # Forward pass\n",
        "        z = w1 * X[i, 0] + w2 * X[i, 1] + b  # Linear combination\n",
        "        y_pred = sigmoid(z)                   # Sigmoid activation\n",
        "\n",
        "        # Binary cross-entropy loss for this sample\n",
        "        epsilon = 1e-15  # Small value to prevent log(0)\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        sample_loss = -(y[i] * np.log(y_pred) + (1 - y[i]) * np.log(1 - y_pred))\n",
        "        total_loss += sample_loss\n",
        "\n",
        "        # Check if prediction is correct\n",
        "        prediction = 1 if y_pred >= 0.5 else 0\n",
        "        if prediction == y[i]:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        # Compute gradients (following your gradient structure)\n",
        "        error = y_pred - y[i]  # Derivative of binary cross-entropy with sigmoid\n",
        "        dw1 = error * X[i, 0]  # Gradient w.r.t w1\n",
        "        dw2 = error * X[i, 1]  # Gradient w.r.t w2\n",
        "        db = error             # Gradient w.r.t bias\n",
        "\n",
        "        # Update parameters (following your update structure)\n",
        "        w1 = w1 - learning_rate * dw1\n",
        "        w2 = w2 - learning_rate * dw2\n",
        "        b = b - learning_rate * db\n",
        "\n",
        "    # Calculate average loss and accuracy for this epoch\n",
        "    avg_loss = total_loss / n\n",
        "    accuracy = correct_predictions / n\n",
        "\n",
        "    # Print progress every 5 epochs (following your print structure)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"{epoch+1:5d} | {avg_loss:25.4f} | {accuracy*100:6.1f}%\")\n",
        "\n",
        "print(f\"\\nFinal parameters:\")\n",
        "print(f\"w1 = {w1:.4f}\")\n",
        "print(f\"w2 = {w2:.4f}\")\n",
        "print(f\"b = {b:.4f}\")\n",
        "\n",
        "# Test predictions on training data\n",
        "print(f\"\\nFinal predictions on training data:\")\n",
        "print(\"Sample | Features | True | Predicted | Probability | Correct\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for i in range(n):\n",
        "    z = w1 * X[i, 0] + w2 * X[i, 1] + b\n",
        "    prob = sigmoid(z)\n",
        "    pred = 1 if prob >= 0.5 else 0\n",
        "    correct = \"✓\" if pred == y[i] else \"✗\"\n",
        "    print(f\"  {i+1:2d}   | {X[i]}   |  {y[i]}   |     {pred}     |   {prob:.3f}   |   {correct}\")\n",
        "\n",
        "# Calculate final accuracy\n",
        "final_predictions = []\n",
        "for i in range(n):\n",
        "    z = w1 * X[i, 0] + w2 * X[i, 1] + b\n",
        "    prob = sigmoid(z)\n",
        "    pred = 1 if prob >= 0.5 else 0\n",
        "    final_predictions.append(pred)\n",
        "\n",
        "final_accuracy = np.mean(np.array(final_predictions) == y)\n",
        "print(f\"\\nFinal Training Accuracy: {final_accuracy*100:.1f}%\")\n",
        "\n",
        "# Decision boundary interpretation\n",
        "print(f\"\\nDecision Boundary Analysis:\")\n",
        "print(f\"The learned decision boundary is: {w1:.3f}*x1 + {w2:.3f}*x2 + {b:.3f} = 0\")\n",
        "if w2 != 0:\n",
        "    print(f\"In slope-intercept form: x2 = {-w1/w2:.3f}*x1 + {-b/w2:.3f}\")\n",
        "\n",
        "# Test on new data point\n",
        "print(f\"\\nTesting on new data point [3, 3]:\")\n",
        "test_x = [3, 3]\n",
        "test_z = w1 * test_x[0] + w2 * test_x[1] + b\n",
        "test_prob = sigmoid(test_z)\n",
        "test_pred = 1 if test_prob >= 0.5 else 0\n",
        "print(f\"Input: {test_x}\")\n",
        "print(f\"Prediction: {test_pred} (probability: {test_prob:.3f})\")\n",
        "print(f\"Classification: {'Positive' if test_pred == 1 else 'Negative'}\")"
      ],
      "metadata": {
        "id": "ZwB4z5mABGq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [2,1,2,1]\n",
        "x2 = [1,2,1,2]\n",
        "y = [1,0,1,0]\n",
        "x1 = np.array([x1])\n",
        "x2 = np.array([x2])\n",
        "y = np.array([y])\n",
        "print(x1)\n",
        "print(x2)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "-nmFhYtPB1re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "lr = 0.1\n",
        "w1 = 0\n",
        "w2 = 0\n",
        "b = 0\n",
        "y_pred = 0"
      ],
      "metadata": {
        "id": "t8Ta9JKsCYp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    y_pred = w1 * x1 + w2 * x2 + b\n",
        "\n",
        "    # Calculate error and loss\n",
        "    error = y - y_pred\n",
        "    loss = np.mean(error**2)\n",
        "\n",
        "    # Calculate predictions and correct predictions\n",
        "    prediction = (y_pred >= 0.5).astype(int)  # Element-wise prediction\n",
        "    correct_predictions = np.sum(prediction == y) # Count correct predictions\n",
        "\n",
        "    # Compute gradients\n",
        "    dw1 = -2 * np.mean(error * x1) # Gradient w.r.t w1\n",
        "    dw2 = -2 * np.mean(error * x2) # Gradient w.r.t w2\n",
        "    db = -2 * np.mean(error)      # Gradient w.r.t bias\n",
        "\n",
        "    # Update parameters\n",
        "    w1 = w1 - lr * dw1\n",
        "    w2 = w2 - lr * dw2\n",
        "    b = b - lr * db\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch + 1) % 1 == 0: # Print every epoch for this small example\n",
        "        accuracy = correct_predictions / len(y[0]) # Calculate accuracy\n",
        "        print(f\"{epoch+1:5d} | {loss:25.4f} | {accuracy*100:6.1f}%\")\n",
        "\n",
        "\n",
        "print(f\"\\nFinal parameters:\")\n",
        "print(f\"w1 = {w1:.4f}\")\n",
        "print(f\"w2 = {w2:.4f}\")\n",
        "print(f\"b = {b:.4f}\")\n",
        "\n",
        "# Test predictions on training data\n",
        "print(f\"\\nFinal predictions on training data:\")\n",
        "print(\"Sample | Features | True | Predicted | Correct\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for i in range(len(y[0])):\n",
        "    z = w1 * x1[0, i] + w2 * x2[0, i] + b\n",
        "    prob = sigmoid(z) # Using sigmoid for probability\n",
        "    pred = 1 if prob >= 0.5 else 0\n",
        "    correct = \"✓\" if pred == y[0, i] else \"✗\"\n",
        "    print(f\"  {i+1:2d}   | [{x1[0, i]} {x2[0, i]}]   |  {y[0, i]}   |     {pred}     |   {correct}\")\n",
        "\n",
        "# Calculate final accuracy\n",
        "final_predictions = (w1 * x1 + w2 * x2 + b >= 0.5).astype(int)\n",
        "final_accuracy = np.mean(final_predictions == y)\n",
        "print(f\"\\nFinal Training Accuracy: {final_accuracy*100:.1f}%\")"
      ],
      "metadata": {
        "id": "21nK89hDCitd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-GnAKr6ZEE5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}